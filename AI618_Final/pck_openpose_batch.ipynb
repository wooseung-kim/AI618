{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08645ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c7c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dir = Path('./pck/masactrl_controlnet/edit_openpose_keypoints') # directory including keypoints.json files\n",
    "gt_dir   = Path('./pck/pose_selected') # directory including keypoints.json files\n",
    "person_idx = 0   # Person index (0-base)\n",
    "\n",
    "pred_files = sorted(pred_dir.glob('*.json'))\n",
    "gt_files   = sorted(gt_dir.glob('*.json'))*10\n",
    "pair_cnt = min(len(pred_files), len(gt_files))\n",
    "if len(pred_files) != len(gt_files):\n",
    "    warnings.warn(f'Directory sizes differ (pred {len(pred_files)}, gt {len(gt_files)}). Evaluating {pair_cnt} pairs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b546d061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT  : 18\n",
      "Pred: 18\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def count_kpts(json_path):\n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    if isinstance(data, list):\n",
    "        data = data[0]\n",
    "    arr = np.asarray(data[\"people\"][0][\"pose_keypoints_2d\"])\n",
    "    return arr.size // 3\n",
    "\n",
    "print(\"GT  :\", count_kpts(gt_files[0]))\n",
    "print(\"Pred:\", count_kpts(pred_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f54025",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "pred_w, pred_h = 512, 512      # prediction image resolution\n",
    "thresh_torso, thresh_head = 0.2, 0.5\n",
    "\n",
    "for idx in range(pair_cnt):\n",
    "    pred_path, gt_path = pred_files[idx], gt_files[idx]\n",
    "    try:\n",
    "        # JSON load (handle list wrapper)\n",
    "        with open(pred_path) as f:\n",
    "            pred_data = json.load(f)\n",
    "        with open(gt_path) as f:\n",
    "            gt_data = json.load(f)\n",
    "        if isinstance(pred_data, list):\n",
    "            pred_data = pred_data[0]\n",
    "        if isinstance(gt_data, list):\n",
    "            gt_data = gt_data[0]\n",
    "\n",
    "        # people extraction\n",
    "        pred_people = pred_data[\"people\"]\n",
    "        gt_people = gt_data[\"people\"]\n",
    "        if not pred_people or not gt_people:\n",
    "            raise ValueError(\"no people\")\n",
    "        if person_idx >= len(pred_people) or person_idx >= len(gt_people):\n",
    "            raise IndexError(\"person_index out of range\")\n",
    "\n",
    "        pred_arr = np.asarray(pred_people[person_idx][\"pose_keypoints_2d\"]).reshape(-1, 3)\n",
    "        gt_arr = np.asarray(gt_people[person_idx][\"pose_keypoints_2d\"]).reshape(-1, 3)\n",
    "\n",
    "        n_common = min(len(pred_arr), len(gt_arr))\n",
    "        kp_pred = pred_arr[:n_common, :2]\n",
    "        kp_gt = gt_arr[:n_common, :2]\n",
    "        conf_gt = gt_arr[:n_common, 2]\n",
    "\n",
    "        # scale GT (768×768 → 512×512)\n",
    "        gt_w, gt_h = gt_data.get(\"canvas_width\"), gt_data.get(\"canvas_height\")\n",
    "        if gt_w is None or gt_h is None:\n",
    "            raise ValueError(\"GT canvas size missing\")\n",
    "        kp_gt *= [pred_w / gt_w, pred_h / gt_h]\n",
    "\n",
    "        # choose indices per format\n",
    "        if n_common >= 25:          # BODY 25\n",
    "            idx_LS, idx_RH = 5, 9\n",
    "            head_pairs = [(17, 18), (15, 16), (0, 1)]\n",
    "        elif n_common == 18:        # BODY 18\n",
    "            idx_LS, idx_RH = 5, 12\n",
    "            head_pairs = [(4, 3), (2, 1), (0, 17)]\n",
    "        elif n_common == 17:        # COCO 17\n",
    "            idx_LS, idx_RH = 5, 12\n",
    "            head_pairs = [(4, 3), (2, 1)]\n",
    "        else:\n",
    "            raise ValueError(\"unexpected keypoint count\")\n",
    "\n",
    "        # torso length\n",
    "        torso_len = np.linalg.norm(kp_gt[idx_LS] - kp_gt[idx_RH])\n",
    "        if torso_len == 0:\n",
    "            raise ValueError(\"zero torso length\")\n",
    "\n",
    "        # head length\n",
    "        head_len = None\n",
    "        for a, b in head_pairs:\n",
    "            if a < n_common and b < n_common and conf_gt[a] > 0.05 and conf_gt[b] > 0.05:\n",
    "                d = np.linalg.norm(kp_gt[a] - kp_gt[b])\n",
    "                if d > 0:\n",
    "                    head_len = d\n",
    "                    break\n",
    "        if head_len is None:\n",
    "            raise ValueError(\"cannot determine head length\")\n",
    "\n",
    "        # distances & correctness\n",
    "        valid = conf_gt > 0.05\n",
    "        dists = np.linalg.norm(kp_pred[valid] - kp_gt[valid], axis=1)\n",
    "        correct_torso = dists < thresh_torso * torso_len\n",
    "        correct_head = dists < thresh_head * head_len\n",
    "\n",
    "        results.append({\n",
    "            \"index\": idx,\n",
    "            \"pred_file\": pred_path.name,\n",
    "            \"gt_file\": gt_path.name,\n",
    "            \"PCK@0.2\": float(correct_torso.mean()),\n",
    "            \"PCKh@0.5\": float(correct_head.mean())\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"index\": idx,\n",
    "            \"pred_file\": pred_path.name,\n",
    "            \"gt_file\": gt_path.name,\n",
    "            \"PCK@0.2\": np.nan,\n",
    "            \"PCKh@0.5\": np.nan,\n",
    "            \"error\": str(e)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8f5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean PCK@0.2 = 0.9111\n"
     ]
    }
   ],
   "source": [
    "valid_pck = [r[\"PCK@0.2\"] for r in results if isinstance(r[\"PCK@0.2\"], float) and not np.isnan(r[\"PCK@0.2\"])]\n",
    "mean_pck_list = np.mean(valid_pck) if valid_pck else float(\"nan\")\n",
    "print(f\"\\nMean PCK@0.2 = {mean_pck_list:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcfe713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean PCKh@0.5 = 0.8889\n"
     ]
    }
   ],
   "source": [
    "valid_pck = [r[\"PCKh@0.5\"] for r in results if isinstance(r[\"PCKh@0.5\"], float) and not np.isnan(r[\"PCKh@0.5\"])]\n",
    "mean_pck_list = np.mean(valid_pck) if valid_pck else float(\"nan\")\n",
    "print(f\"\\nMean PCKh@0.5 = {mean_pck_list:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai618",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
