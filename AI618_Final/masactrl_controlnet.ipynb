{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Self-Attention + ControlNet\n",
    "This notebook supports image generation using the Mutual Self-Attention + ControlNet pipeline proposed in the report.\n",
    "\n",
    "The model that supports ControlNet, `MasaCtrlControlNetPipeline`, is implemented in `diffuser_utils.py`.\n",
    "\n",
    "\n",
    "The code work as follows:\n",
    "\n",
    "You first register the `MutualSelfAttention` editor to the `MasaCtrlControlNetPipeline` using the `register_attention_editor_diffusers` function.\n",
    "Then, if you generate an image using a paired prompt in format ['source prompt', 'edited prompt'] along with a conditioning input image, the output will be saved in the `workdir/exp` directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers (from -r requirements.txt (line 1))\n",
      "  Using cached diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers (from -r requirements.txt (line 2))\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting opencv-python (from -r requirements.txt (line 3))\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting einops (from -r requirements.txt (line 4))\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting omegaconf (from -r requirements.txt (line 5))\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch_lightning (from -r requirements.txt (line 6))\n",
      "  Using cached pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tqdm (from -r requirements.txt (line 7))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from diffusers->-r requirements.txt (line 1)) (8.7.0)\n",
      "Collecting filelock (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub>=0.27.0 (from diffusers->-r requirements.txt (line 1))\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Collecting regex!=2019.12.17 (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting safetensors>=0.3.1 (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting Pillow (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached pillow-11.2.1-cp39-cp39-win_amd64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from transformers->-r requirements.txt (line 2)) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers->-r requirements.txt (line 2))\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers->-r requirements.txt (line 2))\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.27.0->diffusers->-r requirements.txt (line 1))\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers->-r requirements.txt (line 1)) (4.14.0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 5))\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Collecting torch>=2.1.0 (from pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached torch-2.7.1-cp39-cp39-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached torchmetrics-1.7.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from tqdm->-r requirements.txt (line 7)) (0.4.6)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached aiohttp-3.12.12-cp39-cp39-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached frozenlist-1.7.0-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached multidict-6.4.4-cp39-cp39-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached propcache-0.3.2-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached yarl-1.20.1-cp39-cp39-win_amd64.whl.metadata (76 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch_lightning->-r requirements.txt (line 6)) (78.1.1)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.1.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=2.1.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch>=2.1.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.1.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from importlib-metadata->diffusers->-r requirements.txt (line 1)) (3.23.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.1.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->diffusers->-r requirements.txt (line 1))\n",
      "  Using cached charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->diffusers->-r requirements.txt (line 1))\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->diffusers->-r requirements.txt (line 1))\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
      "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "Downloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached aiohttp-3.12.12-cp39-cp39-win_amd64.whl (451 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.4.4-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Using cached yarl-1.20.1-cp39-cp39-win_amd64.whl (87 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.7.0-cp39-cp39-win_amd64.whl (44 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Using cached propcache-0.3.2-cp39-cp39-win_amd64.whl (42 kB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached torch-2.7.1-cp39-cp39-win_amd64.whl (216.0 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached torchmetrics-1.7.2-py3-none-any.whl (962 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl (15 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl (105 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: mpmath, antlr4-python3-runtime, urllib3, tqdm, sympy, safetensors, regex, pyyaml, propcache, Pillow, numpy, networkx, multidict, MarkupSafe, lightning-utilities, idna, fsspec, frozenlist, filelock, einops, charset_normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, opencv-python, omegaconf, jinja2, aiosignal, torch, huggingface-hub, aiohttp, torchmetrics, tokenizers, diffusers, transformers, pytorch_lightning\n",
      "\n",
      "   ----------------------------------------  0/39 [mpmath]\n",
      "   - --------------------------------------  1/39 [antlr4-python3-runtime]\n",
      "   -- -------------------------------------  2/39 [urllib3]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   ---- -----------------------------------  4/39 [sympy]\n",
      "   -------- -------------------------------  8/39 [propcache]\n",
      "   --------- ------------------------------  9/39 [Pillow]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ---------- ----------------------------- 10/39 [numpy]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   -------------- ------------------------- 14/39 [lightning-utilities]\n",
      "   ---------------- ----------------------- 16/39 [fsspec]\n",
      "   -------------------- ------------------- 20/39 [charset_normalizer]\n",
      "   -------------------------- ------------- 26/39 [requests]\n",
      "   --------------------------- ------------ 27/39 [opencv-python]\n",
      "   --------------------------- ------------ 27/39 [opencv-python]\n",
      "   ---------------------------- ----------- 28/39 [omegaconf]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   ------------------------------- -------- 31/39 [torch]\n",
      "   -------------------------------- ------- 32/39 [huggingface-hub]\n",
      "   --------------------------------- ------ 33/39 [aiohttp]\n",
      "   ---------------------------------- ----- 34/39 [torchmetrics]\n",
      "   ---------------------------------- ----- 34/39 [torchmetrics]\n",
      "   ---------------------------------- ----- 34/39 [torchmetrics]\n",
      "   ---------------------------------- ----- 34/39 [torchmetrics]\n",
      "   ------------------------------------ --- 36/39 [diffusers]\n",
      "   ------------------------------------ --- 36/39 [diffusers]\n",
      "   ------------------------------------ --- 36/39 [diffusers]\n",
      "   ------------------------------------ --- 36/39 [diffusers]\n",
      "   ------------------------------------ --- 36/39 [diffusers]\n",
      "   ------------------------------------ --- 36/39 [diffusers]\n",
      "   ------------------------------------ --- 36/39 [diffusers]\n",
      "   ------------------------------------ --- 36/39 [diffusers]\n",
      "   ------------------------------------ --- 36/39 [diffusers]\n",
      "   ------------------------------------ --- 36/39 [diffusers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [transformers]\n",
      "   -------------------------------------- - 38/39 [pytorch_lightning]\n",
      "   -------------------------------------- - 38/39 [pytorch_lightning]\n",
      "   -------------------------------------- - 38/39 [pytorch_lightning]\n",
      "   ---------------------------------------- 39/39 [pytorch_lightning]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.2.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.12 aiosignal-1.3.2 antlr4-python3-runtime-4.9.3 async-timeout-5.0.1 attrs-25.3.0 certifi-2025.4.26 charset_normalizer-3.4.2 diffusers-0.33.1 einops-0.8.1 filelock-3.18.0 frozenlist-1.7.0 fsspec-2025.5.1 huggingface-hub-0.33.0 idna-3.10 jinja2-3.1.6 lightning-utilities-0.14.3 mpmath-1.3.0 multidict-6.4.4 networkx-3.2.1 numpy-2.0.2 omegaconf-2.3.0 opencv-python-4.11.0.86 propcache-0.3.2 pytorch_lightning-2.5.1.post0 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.4 safetensors-0.5.3 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.1 torchmetrics-1.7.2 tqdm-4.67.1 transformers-4.52.4 urllib3-2.4.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (2.7.1)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp39-cp39-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp39-cp39-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hongbin\\anaconda3\\envs\\masatest\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp39-cp39-win_amd64.whl (5.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp39-cp39-win_amd64.whl (2817.1 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\n",
      "  Attempting uninstall: torch\n",
      "\n",
      "    Found existing installation: torch 2.7.1\n",
      "\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "    Uninstalling torch-2.7.1:\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "      Successfully uninstalled torch-2.7.1\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   ---------------------------------------- 3/3 [torchaudio]\n",
      "\n",
      "Successfully installed torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Self-Attention + ControlNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange, repeat\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from diffusers import DDIMScheduler, ControlNetModel\n",
    "\n",
    "from MasaCtrl.masactrl.diffuser_utils import MasaCtrlPipeline, MasaCtrlControlNetPipeline\n",
    "from MasaCtrl.masactrl.masactrl_utils import AttentionBase\n",
    "from MasaCtrl.masactrl.masactrl_utils import regiter_attention_editor_diffusers\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.io import read_image\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.set_device(0)  # set the GPU device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Keyword arguments {'cross_attention_kwargs': {'scale': 0.5}} are not expected by MasaCtrlControlNetPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 16.75it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_path = \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
    "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-openpose\")\n",
    "\n",
    "model = MasaCtrlControlNetPipeline.from_pretrained(model_path, controlnet=controlnet, scheduler=scheduler, cross_attention_kwargs={\"scale\": 0.5}).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistent synthesis with MasaCtrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from MasaCtrl.masactrl.masactrl import MutualSelfAttentionControl\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)\n",
    "\n",
    "out_dir = \"./workdir/exp/\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "sample_count = len(os.listdir(out_dir))\n",
    "out_dir = os.path.join(out_dir, f\"sample_{sample_count}\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "prompts = [\n",
    "    \"1boy, casual, outdoors, standing\",  # source prompt\n",
    "    \"1boy, casual, outdoors, dancing\"  # target prompt\n",
    "]\n",
    "\n",
    "condition_image = \"dataset/poses/dance_03.png\"\n",
    "# load the condition image\n",
    "condition_image = read_image(condition_image).float() / 255.0\n",
    "# rgba to rgb conversion\n",
    "if condition_image.shape[0] == 4:\n",
    "    condition_image = condition_image[:3, :, :]\n",
    "    # resize to 512x512\n",
    "condition_image = F.interpolate(condition_image.unsqueeze(0), size=(512, 512), mode='bilinear', align_corners=False)\n",
    "condition_image = condition_image.to(device)\n",
    "zero_condition = torch.zeros_like(condition_image)\n",
    "condition = torch.cat([zero_condition, condition_image], dim=0)  # concatenate the condition image and zero condition\n",
    "\n",
    "# initialize the noise map\n",
    "start_code = torch.randn([1, 4, 64, 64], device=device)\n",
    "start_code = start_code.expand(len(prompts), -1, -1, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hongbin\\Desktop\\AI618_Final\\MasaCtrl\\masactrl\\diffuser_utils.py:367: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  latent_shape = (batch_size, self.unet.in_channels, height // 8, width // 8)\n",
      "DDIM Sampler: 100%|██████████| 50/50 [18:26<00:00, 22.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# inference the synthesized image without MasaCtrl\n",
    "editor = AttentionBase()\n",
    "regiter_attention_editor_diffusers(model, editor)\n",
    "image_ori = model(prompts, controlnet_conditioning=condition, latents=start_code, guidance_scale=7.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [20:06<00:00, 24.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntheiszed images are saved in ./workdir/exp/sample_4\n"
     ]
    }
   ],
   "source": [
    "# inference the synthesized image with MasaCtrl\n",
    "STEP = 4\n",
    "LAYER = 10\n",
    "\n",
    "# hijack the attention module\n",
    "editor = MutualSelfAttentionControl(STEP, LAYER)\n",
    "regiter_attention_editor_diffusers(model, editor)\n",
    "\n",
    "# inference the synthesized image\n",
    "image_masactrl = model(prompts, controlnet_conditioning=condition, latents=start_code, guidance_scale=7.5)[-1:]\n",
    "\n",
    "# save the synthesized image\n",
    "out_image = torch.cat([image_ori, image_masactrl], dim=0)\n",
    "save_image(out_image, os.path.join(out_dir, f\"all_step{STEP}_layer{LAYER}.png\"))\n",
    "save_image(out_image[0], os.path.join(out_dir, f\"source_step{STEP}_layer{LAYER}.png\"))\n",
    "save_image(out_image[1], os.path.join(out_dir, f\"without_step{STEP}_layer{LAYER}.png\"))\n",
    "save_image(out_image[2], os.path.join(out_dir, f\"masactrl_step{STEP}_layer{LAYER}.png\"))\n",
    "\n",
    "print(\"Syntheiszed images are saved in\", out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd/hbchoe/anaconda3/envs/Masactrl2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange, repeat\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from diffusers import DDIMScheduler, ControlNetModel\n",
    "\n",
    "from MasaCtrl.masactrl.diffuser_utils import MasaCtrlPipeline, MasaCtrlControlNetPipeline\n",
    "from MasaCtrl.masactrl.masactrl_utils import AttentionBase\n",
    "from MasaCtrl.masactrl.masactrl_utils import regiter_attention_editor_diffusers\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.io import read_image\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.set_device(0)  # set the GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MasaCtrl.masactrl.masactrl import MutualSelfAttentionControl\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Keyword arguments {'cross_attention_kwargs': {'scale': 0.5}} are not expected by MasaCtrlControlNetPipeline and will be ignored.\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_path = \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
    "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-openpose\")\n",
    "\n",
    "model = MasaCtrlControlNetPipeline.from_pretrained(model_path, controlnet=controlnet, scheduler=scheduler, cross_attention_kwargs={\"scale\": 0.5}).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"highly detailed, 1boy, standing, facing camera, full body portrait, full-length portrait\",  # source prompt\n",
    "    \"highly detailed, 1boy, dancing, facing camera, full body portrait, full-length portrait\"  # target prompt\n",
    "]\n",
    "\n",
    "condition_image = \"dataset/poses/dance_01.png\"\n",
    "# load the condition image\n",
    "condition_image = read_image(condition_image).float() / 255.0\n",
    "# rgba to rgb conversion\n",
    "if condition_image.shape[0] == 4:\n",
    "    condition_image = condition_image[:3, :, :]\n",
    "    # resize to 512x512\n",
    "condition_image = F.interpolate(condition_image.unsqueeze(0), size=(512, 512), mode='bilinear', align_corners=False)\n",
    "condition_image = condition_image.to(device)\n",
    "zero_condition = torch.zeros_like(condition_image)\n",
    "condition = torch.cat([zero_condition, condition_image], dim=0)  # concatenate the condition image and zero condition\n",
    "\n",
    "# initialize the noise map\n",
    "start_code = torch.randn([1, 4, 64, 64], device=device)\n",
    "start_code = start_code.expand(len(prompts), -1, -1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:53<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# inference the synthesized image without MasaCtrl\n",
    "editor = AttentionBase()\n",
    "regiter_attention_editor_diffusers(model, editor)\n",
    "image_ori = model(prompts, controlnet_conditioning=condition, latents=start_code, guidance_scale=7.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "# Convert the PyTorch tensor to PIL image before saving\n",
    "ToPILImage()(image_ori[0].cpu()).save(\"final_test22/final_test_zero_cond_original.png\")\n",
    "ToPILImage()(image_ori[1].cpu()).save(\"final_test22/final_test_zero_cond_without.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n",
      "Using MutualSelfAttentionControlMaskAuto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:06<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n",
      "Using MutualSelfAttentionControlMaskAuto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:07<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n",
      "Using MutualSelfAttentionControlMaskAuto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:07<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n",
      "Using MutualSelfAttentionControlMaskAuto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:07<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n",
      "Using MutualSelfAttentionControlMaskAuto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:06<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "STEP = 4\n",
    "LAYER = 10\n",
    "# sequential generation\n",
    "\n",
    "folder_path = \"/mnt/hdd/hbchoe/workspace/MasaCtrl/dataset/poses\"\n",
    "output_folder = \"final_test22\"\n",
    "control_image_files = sorted(glob.glob(f\"{folder_path}/*.png\"))\n",
    "\n",
    "# conditioning image preprocess\n",
    "condition_image = \"/mnt/hdd/hbchoe/workspace/MasaCtrl/dataset/poses/dance_03.png\"\n",
    "\n",
    "\n",
    "\n",
    "for file in control_image_files[:5]:\n",
    "    # load the condition image\n",
    "    condition_image = read_image(file).float() / 255.0\n",
    "    # rgba to rgb conversion\n",
    "    if condition_image.shape[0] == 4:\n",
    "        condition_image = condition_image[:3, :, :]\n",
    "        # resize to 512x512\n",
    "    condition_image = F.interpolate(condition_image.unsqueeze(0), size=(512, 512), mode='bilinear', align_corners=False)\n",
    "    condition_image = condition_image.to(device)\n",
    "    zero_condition = torch.zeros_like(condition_image)\n",
    "    condition = torch.cat([zero_condition, condition_image], dim=0)  # concatenate the condition image and zero condition\n",
    "\n",
    "    # inference the synthesized image with MasaCtrl\n",
    "    STEP = 4\n",
    "    LAYER = 10\n",
    "\n",
    "    # hijack the attention module\n",
    "    # editor = MutualSelfAttentionControl(STEP, LAYER)\n",
    "    editor = MutualSelfAttentionControl(STEP, LAYER)\n",
    "    regiter_attention_editor_diffusers(model, editor)\n",
    "\n",
    "    # inference the synthesized image\n",
    "    image_masactrl = model(prompts, controlnet_conditioning=condition, latents=start_code, guidance_scale=7.5)[-1:]\n",
    "    # Save the edited image\n",
    "    file_name, file_ext = os.path.splitext(os.path.basename(file))\n",
    "    # image_masactrl.save(f\"{output_folder}/final_test_{file_name}.png\")  # with attention hijack\n",
    "    save_image(image_masactrl, f\"{output_folder}/final_test_{file_name}.png\")  # with attention hijack\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('ldm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "587aa04bacead72c1ffd459abbe4c8140b72ba2b534b24165b36a2ede3d95042"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
