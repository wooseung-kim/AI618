{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Self-Attention + ControlNet\n",
    "This notebook supports image generation using the Mutual Self-Attention + ControlNet pipeline proposed in the report.\n",
    "\n",
    "The model that supports ControlNet, `MasaCtrlControlNetPipeline`, is implemented in `diffuser_utils.py`.\n",
    "\n",
    "\n",
    "The code work as follows:\n",
    "\n",
    "You first register the `MutualSelfAttention` editor to the `MasaCtrlControlNetPipeline` using the `register_attention_editor_diffusers` function.\n",
    "Then, if you generate an image using a paired prompt in format ['source prompt', 'edited prompt'] along with a conditioning input image, the output will be saved in the `workdir/exp` directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers (from -r requirements.txt (line 1))\n",
      "  Using cached diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers (from -r requirements.txt (line 2))\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting opencv-python (from -r requirements.txt (line 3))\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting einops (from -r requirements.txt (line 4))\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting omegaconf (from -r requirements.txt (line 5))\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch_lightning (from -r requirements.txt (line 6))\n",
      "  Using cached pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from diffusers->-r requirements.txt (line 1)) (8.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from diffusers->-r requirements.txt (line 1)) (3.13.1)\n",
      "Collecting huggingface-hub>=0.27.0 (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached huggingface_hub-0.32.5-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from diffusers->-r requirements.txt (line 1)) (1.26.3)\n",
      "Collecting regex!=2019.12.17 (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting safetensors>=0.3.1 (from diffusers->-r requirements.txt (line 1))\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from diffusers->-r requirements.txt (line 1)) (11.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from transformers->-r requirements.txt (line 2)) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers->-r requirements.txt (line 2))\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers->-r requirements.txt (line 2))\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers->-r requirements.txt (line 2))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers->-r requirements.txt (line 1)) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers->-r requirements.txt (line 1)) (4.14.0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 5))\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=2.1.0 in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from pytorch_lightning->-r requirements.txt (line 6)) (2.7.1+cu118)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached torchmetrics-1.7.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached aiohttp-3.12.12-cp39-cp39-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached frozenlist-1.7.0-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached multidict-6.4.4-cp39-cp39-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached propcache-0.3.2-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached yarl-1.20.1-cp39-cp39-win_amd64.whl.metadata (76 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->-r requirements.txt (line 6))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch_lightning->-r requirements.txt (line 6)) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from torch>=2.1.0->pytorch_lightning->-r requirements.txt (line 6)) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from torch>=2.1.0->pytorch_lightning->-r requirements.txt (line 6)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from torch>=2.1.0->pytorch_lightning->-r requirements.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch_lightning->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from tqdm>=4.27->transformers->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from importlib-metadata->diffusers->-r requirements.txt (line 1)) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from jinja2->torch>=2.1.0->pytorch_lightning->-r requirements.txt (line 6)) (2.1.5)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->diffusers->-r requirements.txt (line 1))\n",
      "  Using cached charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->diffusers->-r requirements.txt (line 1))\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->diffusers->-r requirements.txt (line 1))\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
      "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "Using cached huggingface_hub-0.32.5-py3-none-any.whl (512 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
      "Using cached aiohttp-3.12.12-cp39-cp39-win_amd64.whl (451 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.4.4-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Using cached yarl-1.20.1-cp39-cp39-win_amd64.whl (87 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.7.0-cp39-cp39-win_amd64.whl (44 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Using cached propcache-0.3.2-cp39-cp39-win_amd64.whl (42 kB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached torchmetrics-1.7.2-py3-none-any.whl (962 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl (105 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: antlr4-python3-runtime, urllib3, tqdm, safetensors, regex, pyyaml, propcache, opencv-python, multidict, lightning-utilities, idna, frozenlist, einops, charset_normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, omegaconf, aiosignal, torchmetrics, huggingface-hub, aiohttp, tokenizers, diffusers, transformers, pytorch_lightning\n",
      "\n",
      "   - --------------------------------------  1/29 [urllib3]\n",
      "   ----- ----------------------------------  4/29 [regex]\n",
      "   --------- ------------------------------  7/29 [opencv-python]\n",
      "   --------- ------------------------------  7/29 [opencv-python]\n",
      "   --------- ------------------------------  7/29 [opencv-python]\n",
      "   ---------------- ----------------------- 12/29 [einops]\n",
      "   -------------------- ------------------- 15/29 [attrs]\n",
      "   --------------------------- ------------ 20/29 [omegaconf]\n",
      "   ------------------------------ --------- 22/29 [torchmetrics]\n",
      "   ------------------------------ --------- 22/29 [torchmetrics]\n",
      "   ------------------------------ --------- 22/29 [torchmetrics]\n",
      "   ------------------------------ --------- 22/29 [torchmetrics]\n",
      "   ------------------------------- -------- 23/29 [huggingface-hub]\n",
      "   ------------------------------- -------- 23/29 [huggingface-hub]\n",
      "   --------------------------------- ------ 24/29 [aiohttp]\n",
      "   ----------------------------------- ---- 26/29 [diffusers]\n",
      "   ----------------------------------- ---- 26/29 [diffusers]\n",
      "   ----------------------------------- ---- 26/29 [diffusers]\n",
      "   ----------------------------------- ---- 26/29 [diffusers]\n",
      "   ----------------------------------- ---- 26/29 [diffusers]\n",
      "   ----------------------------------- ---- 26/29 [diffusers]\n",
      "   ----------------------------------- ---- 26/29 [diffusers]\n",
      "   ----------------------------------- ---- 26/29 [diffusers]\n",
      "   ----------------------------------- ---- 26/29 [diffusers]\n",
      "   ----------------------------------- ---- 26/29 [diffusers]\n",
      "   ----------------------------------- ---- 26/29 [diffusers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   ------------------------------------- -- 27/29 [transformers]\n",
      "   -------------------------------------- - 28/29 [pytorch_lightning]\n",
      "   -------------------------------------- - 28/29 [pytorch_lightning]\n",
      "   -------------------------------------- - 28/29 [pytorch_lightning]\n",
      "   -------------------------------------- - 28/29 [pytorch_lightning]\n",
      "   ---------------------------------------- 29/29 [pytorch_lightning]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.12 aiosignal-1.3.2 antlr4-python3-runtime-4.9.3 async-timeout-5.0.1 attrs-25.3.0 certifi-2025.4.26 charset_normalizer-3.4.2 diffusers-0.33.1 einops-0.8.1 frozenlist-1.7.0 huggingface-hub-0.32.5 idna-3.10 lightning-utilities-0.14.3 multidict-6.4.4 omegaconf-2.3.0 opencv-python-4.11.0.86 propcache-0.3.2 pytorch_lightning-2.5.1.post0 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.4 safetensors-0.5.3 tokenizers-0.21.1 torchmetrics-1.7.2 tqdm-4.67.1 transformers-4.52.4 urllib3-2.4.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp39-cp39-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp39-cp39-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages (from torch) (4.14.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "     ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 15.8/15.8 MB 90.9 MB/s eta 0:00:00\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp39-cp39-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 536.2/536.2 kB 17.1 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp39-cp39-win_amd64.whl (2817.1 MB)\n",
      "Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp39-cp39-win_amd64.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 111.3 MB/s eta 0:00:00\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 74.3 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.2/6.2 MB 95.6 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 92.4 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   ------ ---------------------------------  2/12 [pillow]\n",
      "   ------ ---------------------------------  2/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   -------------------- -------------------  6/12 [fsspec]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ---------------------------------------- 12/12 [torchaudio]\n",
      "\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 pillow-11.0.0 sympy-1.13.3 torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Self-Attention + ControlNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange, repeat\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from diffusers import DDIMScheduler, ControlNetModel\n",
    "\n",
    "from MasaCtrl.masactrl.diffuser_utils import MasaCtrlPipeline, MasaCtrlControlNetPipeline\n",
    "from MasaCtrl.masactrl.masactrl_utils import AttentionBase\n",
    "from MasaCtrl.masactrl.masactrl_utils import regiter_attention_editor_diffusers\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.io import read_image\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.set_device(0)  # set the GPU device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Keyword arguments {'cross_attention_kwargs': {'scale': 0.5}} are not expected by MasaCtrlControlNetPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 22.13it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_path = \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
    "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-openpose\")\n",
    "\n",
    "model = MasaCtrlControlNetPipeline.from_pretrained(model_path, controlnet=controlnet, scheduler=scheduler, cross_attention_kwargs={\"scale\": 0.5}).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistent synthesis with MasaCtrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from MasaCtrl.masactrl.masactrl import MutualSelfAttentionControl\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)\n",
    "\n",
    "out_dir = \"./workdir/exp/\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "sample_count = len(os.listdir(out_dir))\n",
    "out_dir = os.path.join(out_dir, f\"sample_{sample_count}\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "prompts = [\n",
    "    \"1boy, casual, outdoors, standing\",  # source prompt\n",
    "    \"1boy, casual, outdoors, dancing\"  # target prompt\n",
    "]\n",
    "\n",
    "condition_image = \"dataset/poses/dance_03.png\"\n",
    "# load the condition image\n",
    "condition_image = read_image(condition_image).float() / 255.0\n",
    "# rgba to rgb conversion\n",
    "if condition_image.shape[0] == 4:\n",
    "    condition_image = condition_image[:3, :, :]\n",
    "    # resize to 512x512\n",
    "condition_image = F.interpolate(condition_image.unsqueeze(0), size=(512, 512), mode='bilinear', align_corners=False)\n",
    "condition_image = condition_image.to(device)\n",
    "zero_condition = torch.zeros_like(condition_image)\n",
    "condition = torch.cat([zero_condition, condition_image], dim=0)  # concatenate the condition image and zero condition\n",
    "\n",
    "# initialize the noise map\n",
    "start_code = torch.randn([1, 4, 64, 64], device=device)\n",
    "start_code = start_code.expand(len(prompts), -1, -1, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hongbin\\Desktop\\AI618_Final\\MasaCtrl\\masactrl\\diffuser_utils.py:367: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  latent_shape = (batch_size, self.unet.in_channels, height // 8, width // 8)\n",
      "DDIM Sampler:   0%|          | 0/50 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m editor \u001b[38;5;241m=\u001b[39m AttentionBase()\n\u001b[0;32m      3\u001b[0m regiter_attention_editor_diffusers(model, editor)\n\u001b[1;32m----> 4\u001b[0m image_ori \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrolnet_conditioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\Desktop\\AI618_Final\\MasaCtrl\\masactrl\\diffuser_utils.py:397\u001b[0m, in \u001b[0;36mMasaCtrlControlNetPipeline.__call__\u001b[1;34m(self, prompt, controlnet_conditioning, batch_size, height, width, num_inference_steps, guidance_scale, eta, latents, unconditioning, neg_prompt, ref_intermediate_latents, return_intermediates, **kwds)\u001b[0m\n\u001b[0;32m    389\u001b[0m         cond \u001b[38;5;241m=\u001b[39m cond\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    391\u001b[0m     cn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrolnet(\n\u001b[0;32m    392\u001b[0m         model_in, t,\n\u001b[0;32m    393\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mtext_embeddings,\n\u001b[0;32m    394\u001b[0m         controlnet_cond\u001b[38;5;241m=\u001b[39mcond,\n\u001b[0;32m    395\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    396\u001b[0m     )\n\u001b[1;32m--> 397\u001b[0m     noise_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdown_block_additional_residuals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcn_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_block_res_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmid_block_additional_residual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcn_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid_block_res_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m     noise_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet(model_in, t, encoder_hidden_states\u001b[38;5;241m=\u001b[39mtext_embeddings)\u001b[38;5;241m.\u001b[39msample\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\diffusers\\models\\unets\\unet_2d_condition.py:1214\u001b[0m, in \u001b[0;36mUNet2DConditionModel.forward\u001b[1;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_adapter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(down_intrablock_additional_residuals) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1212\u001b[0m         additional_residuals[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_residuals\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m down_intrablock_additional_residuals\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 1214\u001b[0m     sample, res_samples \u001b[38;5;241m=\u001b[39m downsample_block(\n\u001b[0;32m   1215\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39msample,\n\u001b[0;32m   1216\u001b[0m         temb\u001b[38;5;241m=\u001b[39memb,\n\u001b[0;32m   1217\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1218\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1219\u001b[0m         cross_attention_kwargs\u001b[38;5;241m=\u001b[39mcross_attention_kwargs,\n\u001b[0;32m   1220\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1221\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madditional_residuals,\n\u001b[0;32m   1222\u001b[0m     )\n\u001b[0;32m   1223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1224\u001b[0m     sample, res_samples \u001b[38;5;241m=\u001b[39m downsample_block(hidden_states\u001b[38;5;241m=\u001b[39msample, temb\u001b[38;5;241m=\u001b[39memb)\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\diffusers\\models\\unets\\unet_2d_blocks.py:1270\u001b[0m, in \u001b[0;36mCrossAttnDownBlock2D.forward\u001b[1;34m(self, hidden_states, temb, encoder_hidden_states, attention_mask, cross_attention_kwargs, encoder_attention_mask, additional_residuals)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1269\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m resnet(hidden_states, temb)\n\u001b[1;32m-> 1270\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;66;03m# apply additional residuals to the output of the last pair of resnet and attention blocks\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(blocks) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m additional_residuals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\diffusers\\models\\transformers\\transformer_2d.py:427\u001b[0m, in \u001b[0;36mTransformer2DModel.forward\u001b[1;34m(self, hidden_states, encoder_hidden_states, timestep, added_cond_kwargs, class_labels, cross_attention_kwargs, attention_mask, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[0;32m    416\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    417\u001b[0m             block,\n\u001b[0;32m    418\u001b[0m             hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    424\u001b[0m             class_labels,\n\u001b[0;32m    425\u001b[0m         )\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;66;03m# 3. Output\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_input_continuous:\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\diffusers\\models\\attention.py:514\u001b[0m, in \u001b[0;36mBasicTransformerBlock.forward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, timestep, cross_attention_kwargs, class_labels, added_cond_kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m cross_attention_kwargs \u001b[38;5;241m=\u001b[39m cross_attention_kwargs\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m cross_attention_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    512\u001b[0m gligen_kwargs \u001b[38;5;241m=\u001b[39m cross_attention_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgligen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 514\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn1(\n\u001b[0;32m    515\u001b[0m     norm_hidden_states,\n\u001b[0;32m    516\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monly_cross_attention \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    517\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcross_attention_kwargs,\n\u001b[0;32m    519\u001b[0m )\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mada_norm_zero\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    522\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m gate_msa\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m attn_output\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\Desktop\\AI618_Final\\MasaCtrl\\masactrl\\masactrl_utils.py:107\u001b[0m, in \u001b[0;36mregiter_attention_editor_diffusers.<locals>.ca_forward.<locals>.forward\u001b[1;34m(x, encoder_hidden_states, attention_mask, context, mask)\u001b[0m\n\u001b[0;32m    105\u001b[0m is_cross \u001b[38;5;241m=\u001b[39m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    106\u001b[0m context \u001b[38;5;241m=\u001b[39m context \u001b[38;5;28;01mif\u001b[39;00m is_cross \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m--> 107\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_v(context)\n\u001b[0;32m    109\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m t: rearrange(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb n (h d) -> (b h) n d\u001b[39m\u001b[38;5;124m'\u001b[39m, h\u001b[38;5;241m=\u001b[39mh), (q, k, v))\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hongbin\\anaconda3\\envs\\masatest2\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# inference the synthesized image without MasaCtrl\n",
    "editor = AttentionBase()\n",
    "regiter_attention_editor_diffusers(model, editor)\n",
    "image_ori = model(prompts, controlnet_conditioning=condition, latents=start_code, guidance_scale=7.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [20:34<00:00, 24.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntheiszed images are saved in ./workdir/exp/sample_0\n"
     ]
    }
   ],
   "source": [
    "# inference the synthesized image with MasaCtrl\n",
    "STEP = 4\n",
    "LAYER = 10\n",
    "\n",
    "# hijack the attention module\n",
    "editor = MutualSelfAttentionControl(STEP, LAYER)\n",
    "regiter_attention_editor_diffusers(model, editor)\n",
    "\n",
    "# inference the synthesized image\n",
    "image_masactrl = model(prompts, controlnet_conditioning=condition, latents=start_code, guidance_scale=7.5)[-1:]\n",
    "\n",
    "# save the synthesized image\n",
    "out_image = torch.cat([image_ori, image_masactrl], dim=0)\n",
    "save_image(out_image, os.path.join(out_dir, f\"all_step{STEP}_layer{LAYER}.png\"))\n",
    "save_image(out_image[0], os.path.join(out_dir, f\"source_step{STEP}_layer{LAYER}.png\"))\n",
    "save_image(out_image[1], os.path.join(out_dir, f\"without_step{STEP}_layer{LAYER}.png\"))\n",
    "save_image(out_image[2], os.path.join(out_dir, f\"masactrl_step{STEP}_layer{LAYER}.png\"))\n",
    "\n",
    "print(\"Syntheiszed images are saved in\", out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd/hbchoe/anaconda3/envs/Masactrl2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange, repeat\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from diffusers import DDIMScheduler, ControlNetModel\n",
    "\n",
    "from MasaCtrl.masactrl.diffuser_utils import MasaCtrlPipeline, MasaCtrlControlNetPipeline\n",
    "from MasaCtrl.masactrl.masactrl_utils import AttentionBase\n",
    "from MasaCtrl.masactrl.masactrl_utils import regiter_attention_editor_diffusers\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.io import read_image\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.set_device(0)  # set the GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MasaCtrl.masactrl.masactrl import MutualSelfAttentionControl\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Keyword arguments {'cross_attention_kwargs': {'scale': 0.5}} are not expected by MasaCtrlControlNetPipeline and will be ignored.\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_path = \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
    "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-openpose\")\n",
    "\n",
    "model = MasaCtrlControlNetPipeline.from_pretrained(model_path, controlnet=controlnet, scheduler=scheduler, cross_attention_kwargs={\"scale\": 0.5}).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"highly detailed, 1boy, standing, facing camera, full body portrait, full-length portrait\",  # source prompt\n",
    "    \"highly detailed, 1boy, dancing, facing camera, full body portrait, full-length portrait\"  # target prompt\n",
    "]\n",
    "\n",
    "condition_image = \"dataset/poses/dance_01.png\"\n",
    "# load the condition image\n",
    "condition_image = read_image(condition_image).float() / 255.0\n",
    "# rgba to rgb conversion\n",
    "if condition_image.shape[0] == 4:\n",
    "    condition_image = condition_image[:3, :, :]\n",
    "    # resize to 512x512\n",
    "condition_image = F.interpolate(condition_image.unsqueeze(0), size=(512, 512), mode='bilinear', align_corners=False)\n",
    "condition_image = condition_image.to(device)\n",
    "zero_condition = torch.zeros_like(condition_image)\n",
    "condition = torch.cat([zero_condition, condition_image], dim=0)  # concatenate the condition image and zero condition\n",
    "\n",
    "# initialize the noise map\n",
    "start_code = torch.randn([1, 4, 64, 64], device=device)\n",
    "start_code = start_code.expand(len(prompts), -1, -1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:53<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# inference the synthesized image without MasaCtrl\n",
    "editor = AttentionBase()\n",
    "regiter_attention_editor_diffusers(model, editor)\n",
    "image_ori = model(prompts, controlnet_conditioning=condition, latents=start_code, guidance_scale=7.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "# Convert the PyTorch tensor to PIL image before saving\n",
    "ToPILImage()(image_ori[0].cpu()).save(\"final_test22/final_test_zero_cond_original.png\")\n",
    "ToPILImage()(image_ori[1].cpu()).save(\"final_test22/final_test_zero_cond_without.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n",
      "Using MutualSelfAttentionControlMaskAuto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:06<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n",
      "Using MutualSelfAttentionControlMaskAuto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:07<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n",
      "Using MutualSelfAttentionControlMaskAuto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:07<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n",
      "Using MutualSelfAttentionControlMaskAuto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:07<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasaCtrl at denoising steps:  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MasaCtrl at U-Net layers:  [10, 11, 12, 13, 14, 15]\n",
      "Using MutualSelfAttentionControlMaskAuto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:06<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "STEP = 4\n",
    "LAYER = 10\n",
    "# sequential generation\n",
    "\n",
    "folder_path = \"/mnt/hdd/hbchoe/workspace/MasaCtrl/dataset/poses\"\n",
    "output_folder = \"final_test22\"\n",
    "control_image_files = sorted(glob.glob(f\"{folder_path}/*.png\"))\n",
    "\n",
    "# conditioning image preprocess\n",
    "condition_image = \"/mnt/hdd/hbchoe/workspace/MasaCtrl/dataset/poses/dance_03.png\"\n",
    "\n",
    "\n",
    "\n",
    "for file in control_image_files[:5]:\n",
    "    # load the condition image\n",
    "    condition_image = read_image(file).float() / 255.0\n",
    "    # rgba to rgb conversion\n",
    "    if condition_image.shape[0] == 4:\n",
    "        condition_image = condition_image[:3, :, :]\n",
    "        # resize to 512x512\n",
    "    condition_image = F.interpolate(condition_image.unsqueeze(0), size=(512, 512), mode='bilinear', align_corners=False)\n",
    "    condition_image = condition_image.to(device)\n",
    "    zero_condition = torch.zeros_like(condition_image)\n",
    "    condition = torch.cat([zero_condition, condition_image], dim=0)  # concatenate the condition image and zero condition\n",
    "\n",
    "    # inference the synthesized image with MasaCtrl\n",
    "    STEP = 4\n",
    "    LAYER = 10\n",
    "\n",
    "    # hijack the attention module\n",
    "    # editor = MutualSelfAttentionControl(STEP, LAYER)\n",
    "    editor = MutualSelfAttentionControl(STEP, LAYER)\n",
    "    regiter_attention_editor_diffusers(model, editor)\n",
    "\n",
    "    # inference the synthesized image\n",
    "    image_masactrl = model(prompts, controlnet_conditioning=condition, latents=start_code, guidance_scale=7.5)[-1:]\n",
    "    # Save the edited image\n",
    "    file_name, file_ext = os.path.splitext(os.path.basename(file))\n",
    "    # image_masactrl.save(f\"{output_folder}/final_test_{file_name}.png\")  # with attention hijack\n",
    "    save_image(image_masactrl, f\"{output_folder}/final_test_{file_name}.png\")  # with attention hijack\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('ldm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "587aa04bacead72c1ffd459abbe4c8140b72ba2b534b24165b36a2ede3d95042"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
